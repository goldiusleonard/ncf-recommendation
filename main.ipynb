{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup and Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install PyTorch GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Requirement already satisfied: torch==2.5.1 in c:\\users\\goldi\\.conda\\envs\\ncf\\lib\\site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision==0.20.1 in c:\\users\\goldi\\.conda\\envs\\ncf\\lib\\site-packages (0.20.1+cu124)\n",
      "Requirement already satisfied: torchaudio==2.5.1 in c:\\users\\goldi\\.conda\\envs\\ncf\\lib\\site-packages (2.5.1+cu124)\n",
      "Requirement already satisfied: filelock in c:\\users\\goldi\\appdata\\roaming\\python\\python310\\site-packages (from torch==2.5.1) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\goldi\\appdata\\roaming\\python\\python310\\site-packages (from torch==2.5.1) (4.8.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\goldi\\appdata\\roaming\\python\\python310\\site-packages (from torch==2.5.1) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\goldi\\appdata\\roaming\\python\\python310\\site-packages (from torch==2.5.1) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\goldi\\appdata\\roaming\\python\\python310\\site-packages (from torch==2.5.1) (2023.9.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\goldi\\.conda\\envs\\ncf\\lib\\site-packages (from torch==2.5.1) (1.13.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\goldi\\appdata\\roaming\\python\\python310\\site-packages (from torchvision==0.20.1) (1.26.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\goldi\\appdata\\roaming\\python\\python310\\site-packages (from torchvision==0.20.1) (9.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\goldi\\appdata\\roaming\\python\\python310\\site-packages (from sympy==1.13.1->torch==2.5.1) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\goldi\\appdata\\roaming\\python\\python310\\site-packages (from jinja2->torch==2.5.1) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\goldi\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\goldi\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\goldi\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\goldi\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\goldi\\appdata\\roaming\\python\\python310\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # Set CUDA_LAUNCH_BLOCKING=1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weâ€™ll use the MovieLens 100K dataset, which contains 100,000 movie ratings from users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0 4808k    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  9 4808k    9  464k    0     0   246k      0  0:00:19  0:00:01  0:00:18  246k\n",
      "100 4808k  100 4808k    0     0  1911k      0  0:00:02  0:00:02 --:--:-- 1914k\n",
      ". : File C:\\Users\\goldi\\Documents\\WindowsPowerShell\\profile.ps1 cannot be loaded because running scripts is disabled \n",
      "on this system. For more information, see about_Execution_Policies at https:/go.microsoft.com/fwlink/?LinkID=135170.\n",
      "At line:1 char:3\n",
      "+ . 'C:\\Users\\goldi\\Documents\\WindowsPowerShell\\profile.ps1'\n",
      "+   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "    + CategoryInfo          : SecurityError: (:) [], PSSecurityException\n",
      "    + FullyQualifiedErrorId : UnauthorizedAccess\n"
     ]
    }
   ],
   "source": [
    "!curl -O -L https://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
    "!powershell -Command \"Expand-Archive -Path 'ml-100k.zip' -DestinationPath '.' -Force\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load user's rating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = pd.read_csv('ml-100k/u.data', sep='\\t', names=['user_id', 'item_id', 'rating', 'timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings data:\n",
      "   user_id  item_id  rating  timestamp\n",
      "0      196      242       3  881250949\n",
      "1      186      302       3  891717742\n",
      "2       22      377       1  878887116\n",
      "3      244       51       2  880606923\n",
      "4      166      346       1  886397596\n"
     ]
    }
   ],
   "source": [
    "print(\"Ratings data:\")\n",
    "print(ratings_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load movie data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv('ml-100k/u.item', sep='|', encoding='latin-1',\n",
    "                       names=['item_id', 'title', 'release_date', 'video_release_date',\n",
    "                              'IMDb_URL', 'unknown', 'Action', 'Adventure', 'Animation',\n",
    "                              'Children', 'Comedy', 'Crime', 'Documentary', 'Drama', 'Fantasy',\n",
    "                              'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi',\n",
    "                              'Thriller', 'War', 'Western'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nMovies data:\n",
      "   item_id              title\n",
      "0        1   Toy Story (1995)\n",
      "1        2   GoldenEye (1995)\n",
      "2        3  Four Rooms (1995)\n",
      "3        4  Get Shorty (1995)\n",
      "4        5     Copycat (1995)\n"
     ]
    }
   ],
   "source": [
    "print(\"nMovies data:\")\n",
    "print(movies_df[['item_id', 'title']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check number of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nTotal number of ratings: 100000\n",
      "Number of unique users: 943\n",
      "Number of unique movies: 1682\n",
      "Rating range: 1 to 5\n",
      "Average rating: 3.53\n"
     ]
    }
   ],
   "source": [
    "print(f\"nTotal number of ratings: {len(ratings_df)}\")\n",
    "print(f\"Number of unique users: {ratings_df['user_id'].nunique()}\")\n",
    "print(f\"Number of unique movies: {ratings_df['item_id'].nunique()}\")\n",
    "print(f\"Rating range: {ratings_df['rating'].min()} to {ratings_df['rating'].max()}\")\n",
    "print(f\"Average rating: {ratings_df['rating'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check distribution of ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='rating', data=ratings_df)\n",
    "plt.title('Distribution of Ratings')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preparation for NCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 80000\n",
      "Test set size: 20000\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split(ratings_df, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(f\"Training set size: {len(train_df)}\")\n",
    "print(f\"Test set size: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 943\n",
      "Number of items: 1682\n"
     ]
    }
   ],
   "source": [
    "num_users = ratings_df['user_id'].max()\n",
    "num_items = ratings_df['item_id'].max()\n",
    "\n",
    "\n",
    "print(f\"Number of users: {num_users}\")\n",
    "print(f\"Number of items: {num_items}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NCFDataset(Dataset):\n",
    "   def __init__(self, df):\n",
    "       self.user_ids = torch.tensor(df['user_id'].values, dtype=torch.long)\n",
    "       self.item_ids = torch.tensor(df['item_id'].values, dtype=torch.long)\n",
    "       self.labels = torch.tensor(df['rating'].values, dtype=torch.float)\n",
    "      \n",
    "   def __len__(self):\n",
    "       return len(self.user_ids)\n",
    "  \n",
    "   def __getitem__(self, idx):\n",
    "       return {\n",
    "           'user_id': self.user_ids[idx],\n",
    "           'item_id': self.item_ids[idx],\n",
    "           'label': self.labels[idx]\n",
    "       }\n",
    "\n",
    "\n",
    "train_dataset = NCFDataset(train_df)\n",
    "test_dataset = NCFDataset(test_df)\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NCF(\n",
      "  (user_embedding_gmf): Embedding(944, 32)\n",
      "  (item_embedding_gmf): Embedding(1683, 32)\n",
      "  (user_embedding_mlp): Embedding(944, 32)\n",
      "  (item_embedding_mlp): Embedding(1683, 32)\n",
      "  (mlp_layers): ModuleList(\n",
      "    (0): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=32, out_features=16, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (output_layer): Linear(in_features=48, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NCF(nn.Module):\n",
    "   def __init__(self, num_users, num_items, embedding_dim=32, mlp_layers=[64, 32, 16]):\n",
    "       super(NCF, self).__init__() \n",
    "\n",
    "       self.user_embedding_gmf = nn.Embedding(num_users + 1, embedding_dim)\n",
    "       self.item_embedding_gmf = nn.Embedding(num_items + 1, embedding_dim)\n",
    "\n",
    "       self.user_embedding_mlp = nn.Embedding(num_users + 1, embedding_dim)\n",
    "       self.item_embedding_mlp = nn.Embedding(num_items + 1, embedding_dim)\n",
    "      \n",
    "       mlp_input_dim = 2 * embedding_dim\n",
    "       self.mlp_layers = nn.ModuleList()\n",
    "       for idx, layer_size in enumerate(mlp_layers):\n",
    "           if idx == 0:\n",
    "               self.mlp_layers.append(nn.Linear(mlp_input_dim, layer_size))\n",
    "           else:\n",
    "               self.mlp_layers.append(nn.Linear(mlp_layers[idx-1], layer_size))\n",
    "           self.mlp_layers.append(nn.ReLU())\n",
    "\n",
    "       self.output_layer = nn.Linear(embedding_dim + mlp_layers[-1], 1)\n",
    "       self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "       self._init_weights()\n",
    "  \n",
    "   def _init_weights(self):\n",
    "       for m in self.modules():\n",
    "           if isinstance(m, nn.Embedding):\n",
    "               nn.init.normal_(m.weight, mean=0.0, std=0.01)\n",
    "           elif isinstance(m, nn.Linear):\n",
    "               nn.init.kaiming_uniform_(m.weight)\n",
    "               if m.bias is not None:\n",
    "                   nn.init.zeros_(m.bias)\n",
    "  \n",
    "   def forward(self, user_ids, item_ids):\n",
    "       user_embedding_gmf = self.user_embedding_gmf(user_ids)\n",
    "       item_embedding_gmf = self.item_embedding_gmf(item_ids)\n",
    "       gmf_vector = user_embedding_gmf * item_embedding_gmf\n",
    "      \n",
    "       user_embedding_mlp = self.user_embedding_mlp(user_ids)\n",
    "       item_embedding_mlp = self.item_embedding_mlp(item_ids)\n",
    "       mlp_vector = torch.cat([user_embedding_mlp, item_embedding_mlp], dim=-1)\n",
    "\n",
    "       for layer in self.mlp_layers:\n",
    "           mlp_vector = layer(mlp_vector)\n",
    "\n",
    "       concat_vector = torch.cat([gmf_vector, mlp_vector], dim=-1)\n",
    "\n",
    "       prediction = self.sigmoid(self.output_layer(concat_vector)).squeeze()\n",
    "\n",
    "       return prediction\n",
    "\n",
    "\n",
    "embedding_dim = 32\n",
    "mlp_layers = [64, 32, 16]\n",
    "model = NCF(num_users, num_items, embedding_dim, mlp_layers).to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/313 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 60\u001b[0m\n\u001b[0;32m     56\u001b[0m history \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_auc\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_ap\u001b[39m\u001b[38;5;124m'\u001b[39m: []}\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 60\u001b[0m    train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m    eval_metrics \u001b[38;5;241m=\u001b[39m evaluate(model, test_loader, criterion, device)\n\u001b[0;32m     64\u001b[0m    history[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[1;32mIn[14], line 15\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, data_loader, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(user_ids, item_ids)\n\u001b[1;32m---> 15\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\goldi\\.conda\\envs\\ncf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\goldi\\.conda\\envs\\ncf\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\goldi\\.conda\\envs\\ncf\\lib\\site-packages\\torch\\nn\\modules\\loss.py:697\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 697\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\goldi\\.conda\\envs\\ncf\\lib\\site-packages\\torch\\nn\\functional.py:3554\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3551\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m   3552\u001b[0m     weight \u001b[38;5;241m=\u001b[39m weight\u001b[38;5;241m.\u001b[39mexpand(new_size)\n\u001b[1;32m-> 3554\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_nn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "\n",
    "\n",
    "def train_epoch(model, data_loader, criterion, optimizer, device):\n",
    "   model.train()\n",
    "   total_loss = 0\n",
    "   for batch in tqdm(data_loader, desc=\"Training\"):\n",
    "       user_ids = batch['user_id'].to(device)\n",
    "       item_ids = batch['item_id'].to(device)\n",
    "       labels = batch['label'].to(device)\n",
    "      \n",
    "       optimizer.zero_grad()\n",
    "       outputs = model(user_ids, item_ids)\n",
    "       loss = criterion(outputs, labels)\n",
    "      \n",
    "       loss.backward()\n",
    "       optimizer.step()\n",
    "      \n",
    "       total_loss += loss.item()\n",
    "  \n",
    "   return total_loss / len(data_loader)\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader, criterion, device):\n",
    "   model.eval()\n",
    "   total_loss = 0\n",
    "   predictions = []\n",
    "   true_labels = []\n",
    "  \n",
    "   with torch.no_grad():\n",
    "       for batch in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "           user_ids = batch['user_id'].to(device)\n",
    "           item_ids = batch['item_id'].to(device)\n",
    "           labels = batch['label'].to(device)\n",
    "          \n",
    "           outputs = model(user_ids, item_ids)\n",
    "           loss = criterion(outputs, labels)\n",
    "           total_loss += loss.item()\n",
    "          \n",
    "           predictions.extend(outputs.cpu().numpy())\n",
    "           true_labels.extend(labels.cpu().numpy())\n",
    "  \n",
    "   from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "   auc = roc_auc_score(true_labels, predictions)\n",
    "   ap = average_precision_score(true_labels, predictions)\n",
    "  \n",
    "   return {\n",
    "       'loss': total_loss / len(data_loader),\n",
    "       'auc': auc,\n",
    "       'ap': ap\n",
    "   }\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "history = {'train_loss': [], 'val_loss': [], 'val_auc': [], 'val_ap': []}\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "   train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "  \n",
    "   eval_metrics = evaluate(model, test_loader, criterion, device)\n",
    "  \n",
    "   history['train_loss'].append(train_loss)\n",
    "   history['val_loss'].append(eval_metrics['loss'])\n",
    "   history['val_auc'].append(eval_metrics['auc'])\n",
    "   history['val_ap'].append(eval_metrics['ap'])\n",
    "  \n",
    "   print(f\"Epoch {epoch+1}/{num_epochs} - \"\n",
    "         f\"Train Loss: {train_loss:.4f}, \"\n",
    "         f\"Val Loss: {eval_metrics['loss']:.4f}, \"\n",
    "         f\"AUC: {eval_metrics['auc']:.4f}, \"\n",
    "         f\"AP: {eval_metrics['ap']:.4f}\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Train Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss During Training')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['val_auc'], label='AUC')\n",
    "plt.plot(history['val_ap'], label='Average Precision')\n",
    "plt.title('Evaluation Metrics')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), 'ncf_model.pth')\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Generating Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recommendations(model, user_id, n=10):\n",
    "   model.eval()\n",
    "   user_ids = torch.tensor([user_id] * num_items, dtype=torch.long).to(device)\n",
    "   item_ids = torch.tensor(range(1, num_items + 1), dtype=torch.long).to(device)\n",
    "  \n",
    "   with torch.no_grad():\n",
    "       predictions = model(user_ids, item_ids).cpu().numpy()\n",
    "  \n",
    "   items_df = pd.DataFrame({\n",
    "       'item_id': range(1, num_items + 1),\n",
    "       'score': predictions\n",
    "   })\n",
    "  \n",
    "   user_rated_items = set(ratings_df[ratings_df['user_id'] == user_id]['item_id'].values)\n",
    "  \n",
    "   items_df = items_df[~items_df['item_id'].isin(user_rated_items)]\n",
    "  \n",
    "   top_n_items = items_df.sort_values('score', ascending=False).head(n)\n",
    "  \n",
    "   recommendations = pd.merge(top_n_items, movies_df[['item_id', 'title']], on='item_id')\n",
    "  \n",
    "   return recommendations[['item_id', 'title', 'score']]\n",
    "\n",
    "\n",
    "test_users = [1, 42, 100]\n",
    "\n",
    "\n",
    "for user_id in test_users:\n",
    "   print(f\"nTop 10 recommendations for user {user_id}:\")\n",
    "   recommendations = generate_recommendations(model, user_id, n=10)\n",
    "   print(recommendations)\n",
    "  \n",
    "   print(f\"nMovies that user {user_id} has rated highly (4-5 stars):\")\n",
    "   user_liked = ratings_df[(ratings_df['user_id'] == user_id) & (ratings_df['rating'] >= 4)]\n",
    "   user_liked = pd.merge(user_liked, movies_df[['item_id', 'title']], on='item_id')\n",
    "   user_liked[['item_id', 'title', 'rating']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Evaluating the Model Further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_metrics(model, test_loader, device):\n",
    "   model.eval()\n",
    "   predictions = []\n",
    "   true_labels = []\n",
    "  \n",
    "   with torch.no_grad():\n",
    "       for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "           user_ids = batch['user_id'].to(device)\n",
    "           item_ids = batch['item_id'].to(device)\n",
    "           labels = batch['label'].to(device)\n",
    "          \n",
    "           outputs = model(user_ids, item_ids)\n",
    "          \n",
    "           predictions.extend(outputs.cpu().numpy())\n",
    "           true_labels.extend(labels.cpu().numpy())\n",
    "  \n",
    "   from sklearn.metrics import roc_auc_score, average_precision_score, precision_recall_curve, accuracy_score\n",
    "  \n",
    "   binary_preds = [1 if p >= 0.5 else 0 for p in predictions]\n",
    "  \n",
    "   auc = roc_auc_score(true_labels, predictions)\n",
    "   ap = average_precision_score(true_labels, predictions)\n",
    "   accuracy = accuracy_score(true_labels, binary_preds)\n",
    "  \n",
    "   precision, recall, thresholds = precision_recall_curve(true_labels, predictions)\n",
    "  \n",
    "   plt.figure(figsize=(10, 6))\n",
    "   plt.plot(recall, precision, label=f'AP={ap:.3f}')\n",
    "   plt.xlabel('Recall')\n",
    "   plt.ylabel('Precision')\n",
    "   plt.title('Precision-Recall Curve')\n",
    "   plt.legend()\n",
    "   plt.grid(True)\n",
    "   plt.show()\n",
    "  \n",
    "   return {\n",
    "       'auc': auc,\n",
    "       'ap': ap,\n",
    "       'accuracy': accuracy\n",
    "   }\n",
    "\n",
    "\n",
    "metrics = evaluate_model_with_metrics(model, test_loader, device)\n",
    "print(f\"AUC: {metrics['auc']:.4f}\")\n",
    "print(f\"Average Precision: {metrics['ap']:.4f}\")\n",
    "print(f\"Accuracy: {metrics['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Cold Start Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_rating_counts = ratings_df.groupby('user_id').size().reset_index(name='count')\n",
    "user_rating_counts['group'] = pd.cut(user_rating_counts['count'],\n",
    "                                   bins=[0, 10, 50, 100, float('inf')],\n",
    "                                   labels=['1-10', '11-50', '51-100', '100+'])\n",
    "\n",
    "\n",
    "print(\"Number of users in each rating frequency group:\")\n",
    "print(user_rating_counts['group'].value_counts())\n",
    "\n",
    "\n",
    "def evaluate_by_user_group(model, ratings_df, user_groups, device):\n",
    "   results = {}\n",
    "  \n",
    "   for group_name, user_ids in user_groups.items():\n",
    "       group_ratings = ratings_df[ratings_df['user_id'].isin(user_ids)]\n",
    "      \n",
    "       group_dataset = NCFDataset(group_ratings)\n",
    "       group_loader = DataLoader(group_dataset, batch_size=256, shuffle=False)\n",
    "      \n",
    "       if len(group_loader) == 0:\n",
    "           continue\n",
    "      \n",
    "       model.eval()\n",
    "       predictions = []\n",
    "       true_labels = []\n",
    "      \n",
    "       with torch.no_grad():\n",
    "           for batch in group_loader:\n",
    "               user_ids = batch['user_id'].to(device)\n",
    "               item_ids = batch['item_id'].to(device)\n",
    "               labels = batch['label'].to(device)\n",
    "              \n",
    "               outputs = model(user_ids, item_ids)\n",
    "              \n",
    "               predictions.extend(outputs.cpu().numpy())\n",
    "               true_labels.extend(labels.cpu().numpy())\n",
    "      \n",
    "       from sklearn.metrics import roc_auc_score\n",
    "       try:\n",
    "           auc = roc_auc_score(true_labels, predictions)\n",
    "           results[group_name] = auc\n",
    "       except:\n",
    "           results[group_name] = None\n",
    "  \n",
    "   return results\n",
    "\n",
    "\n",
    "user_groups = {}\n",
    "for group in user_rating_counts['group'].unique():\n",
    "   users_in_group = user_rating_counts[user_rating_counts['group'] == group]['user_id'].values\n",
    "   user_groups[group] = users_in_group\n",
    "\n",
    "\n",
    "group_performance = evaluate_by_user_group(model, test_df, user_groups, device)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "groups = []\n",
    "aucs = []\n",
    "\n",
    "\n",
    "for group, auc in group_performance.items():\n",
    "   if auc is not None:\n",
    "       groups.append(group)\n",
    "       aucs.append(auc)\n",
    "\n",
    "\n",
    "plt.bar(groups, aucs)\n",
    "plt.xlabel('Number of Ratings per User')\n",
    "plt.ylabel('AUC Score')\n",
    "plt.title('Model Performance by User Rating Frequency (Cold Start Analysis)')\n",
    "plt.ylim(0.5, 1.0)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"AUC scores by user rating frequency:\")\n",
    "for group, auc in group_performance.items():\n",
    "   if auc is not None:\n",
    "       print(f\"{group}: {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Business Insights and Extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_predictions(model, data_loader, device):\n",
    "   model.eval()\n",
    "   predictions = []\n",
    "   true_labels = []\n",
    "  \n",
    "   with torch.no_grad():\n",
    "       for batch in data_loader:\n",
    "           user_ids = batch['user_id'].to(device)\n",
    "           item_ids = batch['item_id'].to(device)\n",
    "           labels = batch['label'].to(device)\n",
    "          \n",
    "           outputs = model(user_ids, item_ids)\n",
    "          \n",
    "           predictions.extend(outputs.cpu().numpy())\n",
    "           true_labels.extend(labels.cpu().numpy())\n",
    "  \n",
    "   results_df = pd.DataFrame({\n",
    "       'true_label': true_labels,\n",
    "       'predicted_score': predictions\n",
    "   })\n",
    "  \n",
    "   plt.figure(figsize=(12, 6))\n",
    "  \n",
    "   plt.subplot(1, 2, 1)\n",
    "   sns.histplot(results_df['predicted_score'], bins=30, kde=True)\n",
    "   plt.title('Distribution of Predicted Scores')\n",
    "   plt.xlabel('Predicted Score')\n",
    "   plt.ylabel('Count')\n",
    "  \n",
    "   plt.subplot(1, 2, 2)\n",
    "   sns.boxplot(x='true_label', y='predicted_score', data=results_df)\n",
    "   plt.title('Predicted Scores by True Label')\n",
    "   plt.xlabel('True Label (0=Disliked, 1=Liked)')\n",
    "   plt.ylabel('Predicted Score')\n",
    "  \n",
    "   plt.tight_layout()\n",
    "   plt.show()\n",
    "  \n",
    "   avg_scores = results_df.groupby('true_label')['predicted_score'].mean()\n",
    "   print(\"Average prediction scores:\")\n",
    "   print(f\"Items user disliked (0): {avg_scores[0]:.4f}\")\n",
    "   print(f\"Items user liked (1): {avg_scores[1]:.4f}\")\n",
    "\n",
    "\n",
    "analyze_predictions(model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ncf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
